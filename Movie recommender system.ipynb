{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import CoClustering, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e5885",
   "metadata": {},
   "source": [
    "## using movielens small dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c98e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\91798\\Desktop\\flame\\FSP\\courses'\\ML\\ml-latest-small\\ml-latest-small\\ratings.csv\")\n",
    "df1\n",
    "df1.set_index(['userId', 'movieId'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d68fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"C:\\Users\\91798\\Desktop\\flame\\FSP\\courses'\\ML\\ml-latest-small\\ml-latest-small\\movies.csv\")\n",
    "df2.set_index('movieId')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create a genres dataframe \n",
    "genresdf = pd.DataFrame()\n",
    "# finding all genres of each movie and creating genres dictionary\n",
    "for index, r in df2.iterrows():\n",
    "    genre_dict = {  \"movieId\": r['movieId'],\n",
    "                    \"title\": r['title'],\n",
    "                    \"Action\": False,\n",
    "                    \"Adventure\": False,\n",
    "                    \"Animation\": False,\n",
    "                    \"Children\": False,\n",
    "                    \"Comedy\": False,\n",
    "                    \"Crime\": False,\n",
    "                    \"Documentary\": False,\n",
    "                    \"Drama\": False,\n",
    "                    \"Fantasy\": False,\n",
    "                    \"Film-Noir\": False,\n",
    "                    \"Horror\": False,\n",
    "                    \"Musical\": False,\n",
    "                    \"Mystery\": False,\n",
    "                    \"Romance\": False,\n",
    "                    \"Sci-Fi\": False,\n",
    "                    \"Thriller\": False,\n",
    "                    \"War\": False,\n",
    "                    \"Western\": False,\n",
    "                 \"IMAX\":False}\n",
    "    \n",
    "    genres = r['genres'].split(\"|\")\n",
    "    if \"(no genres listed)\" not in genres:\n",
    "        for gen in genres:\n",
    "            genre_dict[gen] = True\n",
    "    # appending dictionary values of each row to genres dataframe\n",
    "    genresdf = genresdf.append(genre_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64556fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now adding ratings dataframe and movie genres dataframe into a single dataframe\n",
    "df= df1.merge(genresdf,  on='movieId')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb368275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['rating']).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f960886",
   "metadata": {},
   "source": [
    "## Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2297c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the ratings\n",
    "#scaler = StandardScaler()\n",
    "#df['rating'] = scaler.fit_transform(df['rating'].values.reshape(-1, 1))\n",
    "# Pivot the data to have users as rows and movies as columns\n",
    "df_pivot = df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cad771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the KNN model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_knn.fit(df_pivot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the k most similar users\n",
    "k = 10 # Change this to the desired number of recommendations\n",
    "user_index = 1 # Change this to the desired user ID\n",
    "distances, indices = model_knn.kneighbors(df_pivot.iloc[user_index-1,:].values.reshape(1, -1), n_neighbors=40)\n",
    "\n",
    "# Get the movie recommendations for the user\n",
    "movie_ids = df_pivot.columns[indices.flatten()[1:]]\n",
    "movie_ratings = df_pivot.iloc[user_index-1,:][movie_ids]\n",
    "movie_recommendations = pd.DataFrame({'movieId': movie_ids, 'predicted_rating': movie_ratings.values})\n",
    "\n",
    "# Print the top 10 movie recommendations for the user\n",
    "print('Top {} movie recommendations for user {}:'.format(k, user_index))\n",
    "print(movie_recommendations.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for all users\n",
    "distances, indices = model_knn.kneighbors(df_pivot)\n",
    "all_predictions = []\n",
    "for i in range(len(df_pivot)):\n",
    "    if len(indices[i]) > 1:\n",
    "        user_ratings = df_pivot.iloc[indices[i][1:],:]\n",
    "        user_predictions = user_ratings.mean(axis=0)\n",
    "    else:\n",
    "        user_predictions = pd.Series(np.zeros_like(df_pivot.iloc[0]), index=df_pivot.columns)\n",
    "    all_predictions.append(user_predictions)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = sqrt(mean_squared_error(df_pivot.values.flatten(), pd.concat(all_predictions).values))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa0a20",
   "metadata": {},
   "source": [
    "## SVD-Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Create an SVD algorithm instance\n",
    "algo = SVD(n_epochs=25, verbose=True)\n",
    "\n",
    "# Fit the algorithm to the training set\n",
    "algo.fit(trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e68eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 movie recommendations for user 1\n",
    "user_id = 1\n",
    "movie_ids = [i for i in range(1,df['movieId'].nunique()+1)]\n",
    "movies_rated_by_user = df[df['userId'] == user_id]['movieId']\n",
    "movie_ids_to_pred = list(set(movie_ids)-set(movies_rated_by_user))\n",
    "\n",
    "predicted_ratings = []\n",
    "for movie_id in movie_ids_to_pred:\n",
    "    predicted_rating = algo.predict(str(user_id), str(movie_id)).est\n",
    "    predicted_ratings.append((movie_id, predicted_rating))\n",
    "\n",
    "recommended_movies = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:10]\n",
    "recommended_movies = df[df['movieId'].isin([movie[0] for movie in recommended_movies])][['movieId', 'title']].drop_duplicates().set_index('movieId').loc[[movie[0] for movie in recommended_movies]]['title']\n",
    "print(recommended_movies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the algorithm using RMSE and MAE\n",
    "results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Print the mean RMSE and MAE scores across all folds\n",
    "print(\"Mean RMSE score:\", round(results['test_rmse'].mean(), 3))\n",
    "print(\"Mean MAE score:\", round(results['test_mae'].mean(), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e1310",
   "metadata": {},
   "source": [
    "## Co-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the reader for the Surprise library\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Load the dataset into the Surprise format\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Co-clustering model\n",
    "model_cocluster = CoClustering()\n",
    "model_cocluster.fit(trainset)\n",
    "\n",
    "# Get the top k movie recommendations for a given user\n",
    "k = 10 # Change this to the desired number of recommendations\n",
    "user_id = 20 # Change this to the desired user ID\n",
    "\n",
    "# Get the movies that the user has already rated\n",
    "user_movies = df[df['userId'] == user_id]['movieId'].tolist()\n",
    "\n",
    "# Get the movies that the user has not rated\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "user_anti_testset = filter(lambda x: x[0] == user_id, anti_testset)\n",
    "predictions = model_cocluster.test(user_anti_testset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897789d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the predictions by predicted rating in descending order\n",
    "top_k = sorted(predictions, key=lambda x: x.est, reverse=True)[:k]\n",
    "\n",
    "# Print the top k movie recommendations for the user\n",
    "print('Top {} movie recommendations for user {}:'.format(k, user_id))\n",
    "for i, prediction in enumerate(top_k):\n",
    "    movie_id = prediction.iid\n",
    "    title = df[df['movieId'] == movie_id]['title'].values[0]\n",
    "    predicted_rating = prediction.est\n",
    "    print('{}. {} ({:.2f})'.format(i+1, title, predicted_rating))\n",
    "    \n",
    "    \n",
    "predictions = model_cocluster.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print('RMSE score for Co-clustering model: {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7a52d",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46594d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# Combine the data\n",
    "combined = pd.concat([train, test], axis=0)\n",
    "\n",
    "# Encode the user IDs\n",
    "user_encoder = LabelEncoder()\n",
    "combined['userId'] = user_encoder.fit_transform(combined['userId'])\n",
    "\n",
    "# Encode the movie titles\n",
    "title_encoder = LabelEncoder()\n",
    "combined['movieId'] = title_encoder.fit_transform(combined['title'])\n",
    "\n",
    "# Split the combined data back into training and test sets\n",
    "train = combined.iloc[:train.shape[0], :]\n",
    "test = combined.iloc[train.shape[0]:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the ratings\n",
    "scaler = StandardScaler()\n",
    "train['rating'] = scaler.fit_transform(train['rating'].values.reshape(-1, 1))\n",
    "test['rating'] = scaler.transform(test['rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train[['userId', 'movieId']], train['rating'], epochs=50, batch_size=128, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(test[['userId', 'movieId']], test['rating'])\n",
    "test_rmse = np.sqrt(test_loss)\n",
    "print('Test RMSE score: {:.4f}'.format(test_rmse))\n",
    "\n",
    "# Predict the ratings on the test set\n",
    "test['predicted_rating'] = scaler.inverse_transform(model.predict(test[['userId', 'movieId']]))\n",
    "test['movie_title'] = test['title']\n",
    "\n",
    "# Group the predicted ratings by movie title and calculate the average rating\n",
    "avg_ratings = test[['movie_title', 'predicted_rating']].groupby('movie_title').mean().reset_index()\n",
    "\n",
    "# Print the recommended movies\n",
    "print('Recommended movies:')\n",
    "for _, row in avg_ratings.sort_values(by='predicted_rating', ascending=False).iloc[:10].iterrows():\n",
    "    print('{} ({:.4f})'.format(row['movie_title'], row['predicted_rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cce382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb8441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd42aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
